{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 3. Web Structure Mining: Communities ans Link Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical work, we will focus on Web Structure Mining in which data are interconnected and considered as a network to mine. We will first check if a network satisfies to constraints to be considered as a complex network and then, we will determine how important nodes are within a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathData = \"lesmis.gml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, navigate through the documentation of the networkx package and find how to load networks in the GML format\n",
    "You can have a look to this file by openning it with a basic text editor. Note that the graph is undirected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.read_gml(pathData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community detection\n",
    "In this section, we will focus on community detection algorithm. For this, have a look to the networkx package documentation and apply the following community detection algorithms:\n",
    "\n",
    "1. Kernighanâ€“Lin bipartition algorithm\n",
    "2. Percolation method\n",
    "3. Fluid communities algorithm\n",
    "4. Girvan-Newman method\n",
    "\n",
    "When the number of communities to detect has to be specified as a parameter, you will use the coverage metric to select the appropriate number (ranging from 2 to 5).\n",
    "\n",
    "Finally, for each community algorithm, you will add an attribute to each node of the graph. The value of the attribute will be the identifier of the community tne node belongs to (ranging from 0 to nbCommunity -1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community visualization\n",
    "We will now visualize the result of the communication detection algorithm. For this, we start by filtering out some nodes from the visualisation. Particularly, we would like to filter out nodes that do not belong to any communities according to the percolation method. To do so, you need to create a list that contains the label of nodes belonging to a community according to the percolation method. You can use the following dictionnary to set the visualisation options.\n",
    "\n",
    "```json\n",
    "options = {\n",
    "    'node_color' : colorNode, # a list that contains the community id for the nodes we want to plot\n",
    "    'node_size' : 10000, \n",
    "    'cmap' : plt.get_cmap(\"jet\"),\n",
    "    'node_shape' : 'o',\n",
    "    'with_labels' : True, \n",
    "    \"width\" : 0.1, \n",
    "    \"font_size\" : 15,\n",
    "    \"nodelist\" : nodes, # A list that contains the labels of the nodes we want to plot\n",
    "    \"alpha\" : 0.8   \n",
    "}\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "nx.draw(g,**options)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link prediction\n",
    "We now focus on link prediction and tackle this problem using 2 methods: unsupervised and supervised.\n",
    "\n",
    "### Unsupervised\n",
    "We start by the unsupervised perspective. We first build a Panda Series from the edges of the graph and then select a sample of size 50 from this series.\n",
    "\n",
    "Then, in order to see if metrics we have discussed in this lecture are effective, edges in the sample have to be removed from a copied version of g.\n",
    "\n",
    "We can calculate some metrics to determine the strength of a potential link between two nodes. We will then select the top 50 potential links and compare them to the one we have just removed to assess how effective are these metrics over this dataset. You will apply the following methodology:\n",
    "\n",
    "1. Calculate the metrics for all non-existant pairs of nodes\n",
    "2. Build a dataframe to store these scores and extract the top 50 potential links\n",
    "3. Use the isin function over the sample of edges to count how many removed edges are in the top 50\n",
    "\n",
    "Repeat this process with the following link prediction metrics :\n",
    "\n",
    "1. Resource allocation index\n",
    "2. Jaccard coefficient\n",
    "3. Adamic-Adar index\n",
    "4. Preferential attachment\n",
    "\n",
    "### Supervised\n",
    "\n",
    "From previous results, it is hard to say that the above-used features are outstanding... We now try to combine them in a supervised setting. To achieve this, please carrefully apply the following procedure.\n",
    "\n",
    "1/ Set a variable sizeTestSet to 50, a variable sizeTrainingPositiveSet to the number of edges in g minus the size of the test set and, a variable sizeTrainingSet to 2 times the size of the positive training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeTestSet = 50\n",
    "sizeTrainingPositiveSet = len(g.edges()) - sizeTestSet\n",
    "sizeTrainingSet = 2 * sizeTrainingPositiveSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2/ We will build the positive training set and the test set. To do so, first copy the graph g into g_training. Second, generate a sample of size sizeTestSet, denoted by sampleTest, from the series of edges of g_training. This sample will be your test set (we will apply our model on it and hope the existence of a link will be predicted). Then, remove from g_training the edges in sampleTest. Finally, convert the remaining edges as a series.\n",
    "\n",
    "3/ To balance the training set, we will randomly pick pairs of unconnected vertices (negative class). The number of pairs should be equal to the number of considered connections (positive class) in the training set. Find a way to generate this negative training set and name it sampleNegativeTraining.\n",
    "\n",
    "4/ It is now time to calculate the features for each member of the training and test sets. The features list is presented below:\n",
    "\n",
    "size of the shortest path\n",
    "number of shortest paths\n",
    "for each community algorithm, does the vertices associated to a connection belongs to the same community (except -1) : 1 or 0\n",
    "for each link prediction algorithm, the strength of the connection\n",
    "The feature list is:\n",
    "\n",
    "```json\n",
    "features = [\n",
    "    \"lShortestPath\",\n",
    "    \"nbShortestPath\",\n",
    "    \"bipartition\",\n",
    "    \"percolation\",\n",
    "    \"fluid\",\n",
    "    \"girvan\",\n",
    "    \"resource\",\n",
    "    \"jaccard\",\n",
    "    \"adamic\",\n",
    "    \"preferential\",\n",
    "    \"class\"\n",
    "]```\n",
    "\n",
    "5/ Use the following code (and modify it if necessary) to create 2 empty data frames (one for the training set and the other for the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sampleTraining = pd.concat([samplePositiveTraining,sampleNegativeTraining],ignore_index=True)\n",
    "dfTraining = pd.DataFrame(np.zeros((sizeTrainingSet, 11)), columns=features, index= pd.MultiIndex.from_tuples(sampleTraining))\n",
    "dfTest = pd.DataFrame(np.zeros((sizeTestSet, 11)), columns=features, index= pd.MultiIndex.from_tuples(sampleTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6/ Write a function calculateFeatures with the following specifications:\n",
    "\n",
    "INPUT :\n",
    "\n",
    "* sample: the series of edges you want to calculate the feature values\n",
    "* df: the data frame you want to update\n",
    "* training: True if edges in sample are in the training set and False otherwise\n",
    "* positive: True if training = True and positive instances are considered\n",
    "    \n",
    "OUTPUT\n",
    "* No output\n",
    "\n",
    "OBJECTIVE\n",
    "\n",
    "Update df (the rows such that their indexes are in sample) with the feature values\n",
    "\n",
    "7/ Call the function with the apropriate parameters (tips: it should be called 3 times)\n",
    "\n",
    "8/ Apply the following code and conclude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "features = list(dfTraining.columns[:10])\n",
    "y = dfTraining[\"class\"]\n",
    "X = dfTraining[features]\n",
    "dt = DecisionTreeClassifier(min_samples_split=10, random_state=99)\n",
    "dt.fit(X, y)\n",
    "dt.predict(dfTest[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
